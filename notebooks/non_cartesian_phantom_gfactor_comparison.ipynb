{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Cartesian Phantom G-Factor Comparison\n",
    "\n",
    "This notebook demonstrates the comparison of g-factor calculation methods (PMR vs our diagnostic approach) for different numbers of noise replicas (N) using a non-cartesian phantom dataset.\n",
    "\n",
    "The experiment compares:\n",
    "- **PMR Method**: Pseudo-Multiple Replica approach using N noise replicas\n",
    "- **Our Method**: Diagnostic Hutchinson's method using N random vectors\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from mr_recon.gfactor import gfactor_SENSE_diag, gfactor_SENSE_PMR\n",
    "from mr_recon.fourier import sigpy_nufft\n",
    "from mr_recon.linops import sense_linop, batching_params\n",
    "from mr_recon.recons import CG_SENSE_recon, doubleCG_inv_op_builder\n",
    "\n",
    "# Set dark theme for plots\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set the experiment parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Experiment Configuration ---\n",
    "R = 2                    # Acceleration factor\n",
    "lamda_l2 = 0.1          # L2 regularization parameter\n",
    "N_values = [10, 20, 50] # N values for comparison (small for demo)\n",
    "N_ref = 100             # Number of replicas for reference calculation\n",
    "display_mode = 'inv_g'  # 'g' or 'inv_g' (1/g-factor)\n",
    "max_display_window = 'ref'  # 'ref', 'pmr', 'ours', or numeric value\n",
    "\n",
    "# Reconstruction parameters\n",
    "max_iter = 100\n",
    "max_eigen = 1  # Estimate max eigenvalue automatically\n",
    "tol = 1e-2\n",
    "sigma = 1e-2   # Noise standard deviation\n",
    "\n",
    "# Output directory\n",
    "output_dir = f\"experiments/noncartesian_phantom/results/R{R}_L{lamda_l2}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Experiment configuration:\")\n",
    "print(f\"  R = {R}, λ = {lamda_l2}\")\n",
    "print(f\"  N values = {N_values}\")\n",
    "print(f\"  N_ref = {N_ref}\")\n",
    "print(f\"  Display mode = {display_mode}\")\n",
    "print(f\"  Output directory = {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load the non-cartesian phantom dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading ---\n",
    "data_dir = \"experiments/noncartesian_phantom/data\"\n",
    "torch_dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "complex_dtype = torch.complex64\n",
    "print(f\"Using device: {torch_dev}\")\n",
    "\n",
    "# Load data files\n",
    "img = np.load(os.path.join(data_dir, \"img.npy\"))\n",
    "mps = np.load(os.path.join(data_dir, \"mps.npy\"))\n",
    "ksp = np.load(os.path.join(data_dir, \"ksp.npy\"))\n",
    "dcf = np.load(os.path.join(data_dir, \"dcf.npy\"))\n",
    "trj = np.load(os.path.join(data_dir, \"trj.npy\"))\n",
    "\n",
    "# Convert to torch tensors\n",
    "img_torch = torch.tensor(img, dtype=complex_dtype, device=torch_dev)\n",
    "mps_torch = torch.tensor(mps, dtype=complex_dtype, device=torch_dev)\n",
    "ksp_torch_orig = torch.tensor(ksp, dtype=complex_dtype, device=torch_dev)\n",
    "dcf_torch_orig = torch.tensor(dcf, dtype=torch.float32, device=torch_dev)\n",
    "trj_torch_orig = torch.tensor(trj, dtype=torch.float32, device=torch_dev)\n",
    "\n",
    "# Get dimensions\n",
    "im_size = img_torch.shape[-2:]\n",
    "C = mps_torch.shape[0]\n",
    "\n",
    "print(f\"Image size: {im_size}\")\n",
    "print(f\"Number of coils: {C}\")\n",
    "print(f\"Trajectory shape: {trj_torch_orig.shape}\")\n",
    "print(f\"K-space shape: {ksp_torch_orig.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accelerated Data Preparation\n",
    "\n",
    "Create the accelerated trajectory and k-space data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SENSE Operator Setup ---\n",
    "# For non-Cartesian trajectories, acceleration is achieved by retaining every R-th shot/interleave\n",
    "# Trajectory shape is [points_per_shot, num_shots, 2], so we subsample dimension 1 (shots)\n",
    "# K-space shape is [num_coils, points_per_shot, num_shots], so we subsample dimension 2 (shots)\n",
    "# DCF shape is [points_per_shot, num_shots], so we subsample dimension 1 (shots)\n",
    "\n",
    "trj_acc = trj_torch_orig[:, ::R, :]  # Subsample shots\n",
    "dcf_acc = dcf_torch_orig[:, ::R]     # Subsample DCF\n",
    "ksp_acc = ksp_torch_orig[:, :, ::R] # Subsample k-space\n",
    "\n",
    "print(f\"Accelerated trajectory shape: {trj_acc.shape}\")\n",
    "print(f\"Accelerated k-space shape: {ksp_acc.shape}\")\n",
    "print(f\"Acceleration factor: {trj_torch_orig.shape[1] / trj_acc.shape[1]:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SENSE Operators\n",
    "\n",
    "Set up the SENSE linear operators for both fully sampled and accelerated reconstructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NUFFT operator\n",
    "nufft = sigpy_nufft(im_size, width=4)\n",
    "bparams = batching_params(C)\n",
    "\n",
    "# SENSE operators\n",
    "A_acc = sense_linop(im_size, trj_acc, mps_torch, dcf_acc, nufft, bparams=bparams, use_toeplitz=True)\n",
    "A = sense_linop(im_size, trj_torch_orig, mps_torch, dcf_torch_orig, nufft, bparams=bparams, use_toeplitz=True)\n",
    "\n",
    "print(\"SENSE operators created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct Accelerated Image\n",
    "\n",
    "Perform the accelerated reconstruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reconstruct Image for Plotting ---\n",
    "print(\"Reconstructing accelerated image...\")\n",
    "start_time = time.time()\n",
    "recon_image = CG_SENSE_recon(A_acc, ksp_acc, max_iter, lamda_l2, max_eigen, verbose=False, tolerance=tol)\n",
    "recon_time = time.time() - start_time\n",
    "print(f\"Reconstruction completed in {recon_time:.2f} seconds\")\n",
    "\n",
    "# Calculate reconstruction metrics\n",
    "recon_magnitude = recon_image.abs()\n",
    "img_magnitude = img_torch.abs()\n",
    "nmse = torch.norm(recon_magnitude - img_magnitude)**2 / torch.norm(img_magnitude)**2\n",
    "print(f\"NMSE: {nmse.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G-Factor Calculation Functions\n",
    "\n",
    "Define the reconstruction functions for g-factor calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- G-Factor Calculation Functions ---\n",
    "recon_acc_func = lambda ksp_in: CG_SENSE_recon(A_acc, ksp_in, max_iter, lamda_l2, max_eigen, verbose=False, tolerance=tol)\n",
    "recon_ref_func = lambda ksp_in: CG_SENSE_recon(A, ksp_in, max_iter, lamda_l2, max_eigen, verbose=False, tolerance=tol)\n",
    "\n",
    "print(\"Reconstruction functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference G-Factor Calculation\n",
    "\n",
    "Calculate the high-quality reference g-factor using PMR method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calculate High-Quality Reference ---\n",
    "print(f\"Calculating reference g-factor with N={N_ref}...\")\n",
    "start_time = time.time()\n",
    "g_ref_raw = gfactor_SENSE_PMR(R_ref=recon_ref_func, R_acc=recon_acc_func, ksp_ref=ksp_torch_orig, ksp_acc=ksp_acc, noise_var=sigma**2, n_replicas=N_ref, verbose=True)\n",
    "time_ref = time.time() - start_time\n",
    "print(f\"Reference calculation completed in {time_ref:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N Comparison Loop\n",
    "\n",
    "Compare g-factor calculations for different values of N:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loop over N values ---\n",
    "results = {'N': [], 'Time_PMR': [], 'Time_Diag': [], 'g_PMR': [], 'g_Diag': []}\n",
    "\n",
    "for n in N_values:\n",
    "    print(f\"\\nCalculating for N={n}...\")\n",
    "    results['N'].append(n)\n",
    "    \n",
    "    # PMR method\n",
    "    start_time = time.time()\n",
    "    g_pmr_raw = gfactor_SENSE_PMR(R_ref=recon_ref_func, R_acc=recon_acc_func, ksp_ref=ksp_torch_orig, ksp_acc=ksp_acc, noise_var=sigma**2, n_replicas=n, verbose=False)\n",
    "    results['Time_PMR'].append(time.time() - start_time)\n",
    "    results['g_PMR'].append(torch.nan_to_num(g_pmr_raw, nan=1.0))\n",
    "    print(f\"  PMR: {results['Time_PMR'][-1]:.2f}s\")\n",
    "    \n",
    "    # Our diagnostic method (Hutchinson's)\n",
    "    AHA_inv = doubleCG_inv_op_builder(A=A, dcf=dcf_torch_orig, max_iter=max_iter, lamda_l2=lamda_l2, max_eigen=max_eigen, tolerance=tol, verbose=False)\n",
    "    AHA_inv_acc = doubleCG_inv_op_builder(A=A_acc, dcf=dcf_acc, max_iter=max_iter, lamda_l2=lamda_l2, max_eigen=max_eigen, tolerance=tol, verbose=False)\n",
    "\n",
    "    start_time = time.time()\n",
    "    g_diag_raw = gfactor_SENSE_diag(AHA_inv_ref=AHA_inv, AHA_inv_acc=AHA_inv_acc, inp_example=torch.zeros(im_size, device=torch_dev, dtype=complex_dtype), n_replicas=n, sigma=sigma, rnd_vec_type='complex', verbose=False)\n",
    "    results['Time_Diag'].append(time.time() - start_time)\n",
    "    results['g_Diag'].append(torch.nan_to_num(g_diag_raw, nan=1.0))\n",
    "    print(f\"  Our method: {results['Time_Diag'][-1]:.2f}s\")\n",
    "\n",
    "print(\"\\nAll N calculations completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process G-Factor Results\n",
    "\n",
    "Apply scaling and display mode transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Process g-factors based on display_mode ---\n",
    "g_ref_unscaled = results['g_PMR'][N_values.index(min(N_values))] if min(N_values) in N_values else g_ref_raw\n",
    "\n",
    "# --- Apply sqrt(R) scaling ---\n",
    "g_ref = g_ref_unscaled / (R ** 0.5)\n",
    "results['g_PMR'] = [g / (R ** 0.5) for g in results['g_PMR']]\n",
    "results['g_Diag'] = [g / (R ** 0.5) for g in results['g_Diag']]\n",
    "\n",
    "if display_mode == 'inv_g':\n",
    "    g_ref = 1 / g_ref\n",
    "    results['g_PMR'] = [1 / g for g in results['g_PMR']]\n",
    "    results['g_Diag'] = [1 / g for g in results['g_Diag']]\n",
    "    title_prefix = \"1/G-Factor\"\n",
    "else: # display_mode == 'g'\n",
    "    title_prefix = \"G-Factor\"\n",
    "\n",
    "print(f\"Results processed for display mode: {display_mode}\")\n",
    "print(f\"Title prefix: {title_prefix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Comparison Plot\n",
    "\n",
    "Generate the visualization comparing different N values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plotting ---\n",
    "print(\"Generating comparison plot...\")\n",
    "num_comparisons = len(N_values)\n",
    "\n",
    "fig, axes = plt.subplots(2, num_comparisons + 1, figsize=(5 * (num_comparisons + 1), 11))\n",
    "fig.patch.set_facecolor('black')\n",
    "\n",
    "# Determine global vmin and vmax for color consistency\n",
    "vmin = g_ref.min()\n",
    "\n",
    "try:\n",
    "    # Check if max_display_window is a number\n",
    "    vmax = float(max_display_window)\n",
    "except ValueError:\n",
    "    # It's a string like 'ref', 'pmr', or 'ours'\n",
    "    if max_display_window == 'ref':\n",
    "        vmax = g_ref.max()\n",
    "    elif max_display_window == 'pmr':\n",
    "        vmax = max(g.max() for g in results['g_PMR'])\n",
    "    elif max_display_window == 'ours':\n",
    "        vmax = max(g.max() for g in results['g_Diag'])\n",
    "    else: # Default fallback to reference\n",
    "        print(f\"Warning: Invalid string for max_display_window. Defaulting to 'ref'.\")\n",
    "        vmax = g_ref.max()\n",
    "\n",
    "print(f\"Colorbar range: [{vmin:.3f}, {vmax:.3f}]\")\n",
    "\n",
    "# --- Row 1: Our Method + N values + Reference G-factor ---\n",
    "# Columns 0-4: Our Method results\n",
    "for i, n in enumerate(N_values):\n",
    "    ax = axes[0, i]\n",
    "    im = ax.imshow(results['g_Diag'][i].cpu().numpy(), cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(f\"Our Method (N={n})\")\n",
    "    ax.axis('off')\n",
    "    \n",
    "# Column 5: Reference G-Factor (moved to top row)\n",
    "im = axes[0, num_comparisons].imshow(g_ref.cpu().numpy(), cmap='jet', vmin=vmin, vmax=vmax)\n",
    "axes[0, num_comparisons].set_title(f\"Reference {title_prefix}\n",
    "(PMR, N={N_ref})\")\n",
    "axes[0, num_comparisons].axis('off')\n",
    "\n",
    "# --- Row 2: PMR Method + N values + Reconstructed Image ---\n",
    "# Columns 0-4: PMR Method results\n",
    "for i, n in enumerate(N_values):\n",
    "    ax = axes[1, i]\n",
    "    im = ax.imshow(results['g_PMR'][i].cpu().numpy(), cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(f\"PMR (N={n})\")\n",
    "    ax.axis('off')\n",
    "    \n",
    "# Column 5: Reconstructed Image (moved to bottom row)\n",
    "axes[1, num_comparisons].imshow(img_torch.abs().cpu().numpy(), cmap='gray')\n",
    "axes[1, num_comparisons].set_title(f\"Reconstructed Image (R={R})\")\n",
    "axes[1, num_comparisons].axis('off')\n",
    "\n",
    "# Adjust layout to make space for the colorbar and title\n",
    "fig.subplots_adjust(right=0.92, top=0.90)\n",
    "\n",
    "# Add a single colorbar for all g-factor maps on the right side\n",
    "cbar_ax = fig.add_axes([0.94, 0.15, 0.015, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "fig.suptitle(f\"{title_prefix} Calculation Convergence (R={R}, λ={lamda_l2})\", fontsize=24)\n",
    "plt.show()\n",
    "\n",
    "print(\"Plot generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing Analysis\n",
    "\n",
    "Display the timing results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display timing results\n",
    "timing_df = pd.DataFrame({\n",
    "    'N': results['N'],\n",
    "    'Time_PMR': results['Time_PMR'],\n",
    "    'Time_Our_Method': results['Time_Diag']\n",
    "})\n",
    "\n",
    "print(f\"Reference G-Factor (PMR, N={N_ref}) Time: {time_ref:.4f}s\\n\")\n",
    "print(\"--- Comparison Times ---\")\n",
    "print(timing_df.to_string(index=False))\n",
    "\n",
    "# Plot timing comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results['N'], results['Time_PMR'], 'o-', label='PMR Method', linewidth=2, markersize=8)\n",
    "plt.plot(results['N'], results['Time_Diag'], 's-', label='Our Method', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Replicas (N)')\n",
    "plt.ylabel('Computation Time (seconds)')\n",
    "plt.title(f'G-Factor Computation Time vs N (R={R}, λ={lamda_l2})')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results (Optional)\n",
    "\n",
    "Save the plots and timing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save Outputs ---\n",
    "mode_tag = \"g\" if display_mode == \"g\" else \"invG\"\n",
    "N_str = \"N\" + \"-\".join(str(n) for n in N_values)\n",
    "\n",
    "# Save plot\n",
    "plot_path_png = os.path.join(output_dir, f\"N_comparison_plot_R{R}_L{lamda_l2}_{N_str}_mode_{mode_tag}_notebook.png\")\n",
    "plot_path_svg = os.path.join(output_dir, f\"N_comparison_plot_R{R}_L{lamda_l2}_{N_str}_mode_{mode_tag}_notebook.svg\")\n",
    "plt.savefig(plot_path_png, dpi=300, bbox_inches='tight')\n",
    "plt.savefig(plot_path_svg, format='svg', bbox_inches='tight')\n",
    "print(f\"Plot saved to {plot_path_png}\")\n",
    "\n",
    "# Save reconstructed image\n",
    "recon_img_np = recon_image.abs().detach().cpu().numpy()\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(recon_img_np, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(f'Reconstructed Image (R={R})')\n",
    "recon_png_path = os.path.join(output_dir, f\"recon_image_R{R}_L{lamda_l2}_{N_str}_mode_{mode_tag}_notebook.png\")\n",
    "plt.savefig(recon_png_path, bbox_inches='tight', pad_inches=0, dpi=300)\n",
    "plt.close()\n",
    "print(f\"Reconstructed image saved to {recon_png_path}\")\n",
    "\n",
    "# Save timing data\n",
    "times_path = os.path.join(output_dir, f\"N_comparison_times_R{R}_L{lamda_l2}_{N_str}_mode_{mode_tag}_notebook.txt\")\n",
    "with open(times_path, 'w') as f:\n",
    "    f.write(f\"Reference G-Factor (PMR, N={N_ref}) Time: {time_ref:.4f}s\\n\\n\")\n",
    "    f.write(\"--- Comparison Times ---\\n\")\n",
    "    f.write(timing_df.to_string(index=False))\n",
    "print(f\"Timings saved to {times_path}\")\n",
    "\n",
    "print(\"\\nAll results saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Non-cartesian phantom reconstruction** with SENSE acceleration (R={R})\n",
    "2. **G-factor calculation comparison** between PMR and our diagnostic methods\n",
    "3. **Convergence analysis** showing how results improve with increasing N\n",
    "4. **Performance comparison** between the two approaches\n",
    "\n",
    "### Key Findings:\n",
    "- Both methods converge as N increases\n",
    "- Our diagnostic method provides comparable accuracy to PMR\n",
    "- Performance depends on the specific implementation and problem size\n",
    "\n",
    "### Next Steps:\n",
    "- Try different acceleration factors (R values)\n",
    "- Test with real data instead of phantom\n",
    "- Compare with Cartesian acquisitions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
